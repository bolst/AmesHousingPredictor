{
   "cells": [
      {
         "cell_type": "markdown",
         "id": "352eafe6",
         "metadata": {},
         "source": [
            "# Phase 2: Model Training and Experimentation\n",
            "\n",
            "This notebook will focus on training and optimizing our model. Our objectives include\n",
            "1. Experiment tracking with MLflow\n",
            "2. Cross-validation\n",
            "3. Hyperparameter optimization\n",
            "4. Model evaluation and selection\n",
            "5. Model versioning and registration"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 1,
         "id": "e963f08b",
         "metadata": {
            "execution": {
               "iopub.execute_input": "2025-11-05T05:03:52.711998Z",
               "iopub.status.busy": "2025-11-05T05:03:52.711754Z",
               "iopub.status.idle": "2025-11-05T05:03:53.495768Z",
               "shell.execute_reply": "2025-11-05T05:03:53.495471Z"
            }
         },
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Requirement already satisfied: mlflow in /Users/mak/miniforge3/lib/python3.12/site-packages (3.5.1)\r\n",
                  "Requirement already satisfied: optuna in /Users/mak/miniforge3/lib/python3.12/site-packages (4.5.0)\r\n",
                  "Requirement already satisfied: mlflow-skinny==3.5.1 in /Users/mak/miniforge3/lib/python3.12/site-packages (from mlflow) (3.5.1)\r\n",
                  "Requirement already satisfied: mlflow-tracing==3.5.1 in /Users/mak/miniforge3/lib/python3.12/site-packages (from mlflow) (3.5.1)\r\n",
                  "Requirement already satisfied: Flask-CORS<7 in /Users/mak/miniforge3/lib/python3.12/site-packages (from mlflow) (6.0.1)\r\n",
                  "Requirement already satisfied: Flask<4 in /Users/mak/miniforge3/lib/python3.12/site-packages (from mlflow) (3.1.2)\r\n",
                  "Requirement already satisfied: alembic!=1.10.0,<2 in /Users/mak/miniforge3/lib/python3.12/site-packages (from mlflow) (1.17.1)\r\n",
                  "Requirement already satisfied: cryptography<47,>=43.0.0 in /Users/mak/miniforge3/lib/python3.12/site-packages (from mlflow) (46.0.3)\r\n",
                  "Requirement already satisfied: docker<8,>=4.0.0 in /Users/mak/miniforge3/lib/python3.12/site-packages (from mlflow) (7.1.0)\r\n",
                  "Requirement already satisfied: graphene<4 in /Users/mak/miniforge3/lib/python3.12/site-packages (from mlflow) (3.4.3)\r\n",
                  "Requirement already satisfied: gunicorn<24 in /Users/mak/miniforge3/lib/python3.12/site-packages (from mlflow) (23.0.0)\r\n",
                  "Requirement already satisfied: matplotlib<4 in /Users/mak/miniforge3/lib/python3.12/site-packages (from mlflow) (3.10.6)\r\n",
                  "Requirement already satisfied: numpy<3 in /Users/mak/miniforge3/lib/python3.12/site-packages (from mlflow) (2.3.3)\r\n",
                  "Requirement already satisfied: pandas<3 in /Users/mak/miniforge3/lib/python3.12/site-packages (from mlflow) (2.3.3)\r\n",
                  "Requirement already satisfied: pyarrow<22,>=4.0.0 in /Users/mak/miniforge3/lib/python3.12/site-packages (from mlflow) (21.0.0)\r\n",
                  "Requirement already satisfied: scikit-learn<2 in /Users/mak/miniforge3/lib/python3.12/site-packages (from mlflow) (1.7.2)\r\n",
                  "Requirement already satisfied: scipy<2 in /Users/mak/miniforge3/lib/python3.12/site-packages (from mlflow) (1.16.2)\r\n",
                  "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /Users/mak/miniforge3/lib/python3.12/site-packages (from mlflow) (2.0.44)\r\n",
                  "Requirement already satisfied: cachetools<7,>=5.0.0 in /Users/mak/miniforge3/lib/python3.12/site-packages (from mlflow-skinny==3.5.1->mlflow) (6.2.1)\r\n",
                  "Requirement already satisfied: click<9,>=7.0 in /Users/mak/miniforge3/lib/python3.12/site-packages (from mlflow-skinny==3.5.1->mlflow) (8.3.0)\r\n",
                  "Requirement already satisfied: cloudpickle<4 in /Users/mak/miniforge3/lib/python3.12/site-packages (from mlflow-skinny==3.5.1->mlflow) (3.1.2)\r\n",
                  "Requirement already satisfied: databricks-sdk<1,>=0.20.0 in /Users/mak/miniforge3/lib/python3.12/site-packages (from mlflow-skinny==3.5.1->mlflow) (0.72.0)\r\n",
                  "Requirement already satisfied: fastapi<1 in /Users/mak/miniforge3/lib/python3.12/site-packages (from mlflow-skinny==3.5.1->mlflow) (0.120.1)\r\n",
                  "Requirement already satisfied: gitpython<4,>=3.1.9 in /Users/mak/miniforge3/lib/python3.12/site-packages (from mlflow-skinny==3.5.1->mlflow) (3.1.45)\r\n",
                  "Requirement already satisfied: importlib_metadata!=4.7.0,<9,>=3.7.0 in /Users/mak/miniforge3/lib/python3.12/site-packages (from mlflow-skinny==3.5.1->mlflow) (8.7.0)\r\n",
                  "Requirement already satisfied: opentelemetry-api<3,>=1.9.0 in /Users/mak/miniforge3/lib/python3.12/site-packages (from mlflow-skinny==3.5.1->mlflow) (1.38.0)\r\n",
                  "Requirement already satisfied: opentelemetry-proto<3,>=1.9.0 in /Users/mak/miniforge3/lib/python3.12/site-packages (from mlflow-skinny==3.5.1->mlflow) (1.38.0)\r\n",
                  "Requirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in /Users/mak/miniforge3/lib/python3.12/site-packages (from mlflow-skinny==3.5.1->mlflow) (1.38.0)\r\n",
                  "Requirement already satisfied: packaging<26 in /Users/mak/miniforge3/lib/python3.12/site-packages (from mlflow-skinny==3.5.1->mlflow) (25.0)\r\n",
                  "Requirement already satisfied: protobuf<7,>=3.12.0 in /Users/mak/miniforge3/lib/python3.12/site-packages (from mlflow-skinny==3.5.1->mlflow) (6.31.1)\r\n",
                  "Requirement already satisfied: pydantic<3,>=1.10.8 in /Users/mak/miniforge3/lib/python3.12/site-packages (from mlflow-skinny==3.5.1->mlflow) (2.11.10)\r\n",
                  "Requirement already satisfied: python-dotenv<2,>=0.19.0 in /Users/mak/miniforge3/lib/python3.12/site-packages (from mlflow-skinny==3.5.1->mlflow) (1.2.1)\r\n",
                  "Requirement already satisfied: pyyaml<7,>=5.1 in /Users/mak/miniforge3/lib/python3.12/site-packages (from mlflow-skinny==3.5.1->mlflow) (6.0.3)\r\n",
                  "Requirement already satisfied: requests<3,>=2.17.3 in /Users/mak/miniforge3/lib/python3.12/site-packages (from mlflow-skinny==3.5.1->mlflow) (2.32.4)\r\n",
                  "Requirement already satisfied: sqlparse<1,>=0.4.0 in /Users/mak/miniforge3/lib/python3.12/site-packages (from mlflow-skinny==3.5.1->mlflow) (0.5.3)\r\n",
                  "Requirement already satisfied: typing-extensions<5,>=4.0.0 in /Users/mak/miniforge3/lib/python3.12/site-packages (from mlflow-skinny==3.5.1->mlflow) (4.15.0)\r\n",
                  "Requirement already satisfied: uvicorn<1 in /Users/mak/miniforge3/lib/python3.12/site-packages (from mlflow-skinny==3.5.1->mlflow) (0.38.0)\r\n",
                  "Requirement already satisfied: Mako in /Users/mak/miniforge3/lib/python3.12/site-packages (from alembic!=1.10.0,<2->mlflow) (1.3.10)\r\n",
                  "Requirement already satisfied: cffi>=2.0.0 in /Users/mak/miniforge3/lib/python3.12/site-packages (from cryptography<47,>=43.0.0->mlflow) (2.0.0)\r\n",
                  "Requirement already satisfied: google-auth~=2.0 in /Users/mak/miniforge3/lib/python3.12/site-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==3.5.1->mlflow) (2.42.1)\r\n",
                  "Requirement already satisfied: urllib3>=1.26.0 in /Users/mak/miniforge3/lib/python3.12/site-packages (from docker<8,>=4.0.0->mlflow) (2.5.0)\r\n",
                  "Requirement already satisfied: starlette<0.50.0,>=0.40.0 in /Users/mak/miniforge3/lib/python3.12/site-packages (from fastapi<1->mlflow-skinny==3.5.1->mlflow) (0.49.1)\r\n",
                  "Requirement already satisfied: annotated-doc>=0.0.2 in /Users/mak/miniforge3/lib/python3.12/site-packages (from fastapi<1->mlflow-skinny==3.5.1->mlflow) (0.0.3)\r\n",
                  "Requirement already satisfied: blinker>=1.9.0 in /Users/mak/miniforge3/lib/python3.12/site-packages (from Flask<4->mlflow) (1.9.0)\r\n",
                  "Requirement already satisfied: itsdangerous>=2.2.0 in /Users/mak/miniforge3/lib/python3.12/site-packages (from Flask<4->mlflow) (2.2.0)\r\n",
                  "Requirement already satisfied: jinja2>=3.1.2 in /Users/mak/miniforge3/lib/python3.12/site-packages (from Flask<4->mlflow) (3.1.6)\r\n",
                  "Requirement already satisfied: markupsafe>=2.1.1 in /Users/mak/miniforge3/lib/python3.12/site-packages (from Flask<4->mlflow) (3.0.3)\r\n",
                  "Requirement already satisfied: werkzeug>=3.1.0 in /Users/mak/miniforge3/lib/python3.12/site-packages (from Flask<4->mlflow) (3.1.3)\r\n",
                  "Requirement already satisfied: gitdb<5,>=4.0.1 in /Users/mak/miniforge3/lib/python3.12/site-packages (from gitpython<4,>=3.1.9->mlflow-skinny==3.5.1->mlflow) (4.0.12)\r\n",
                  "Requirement already satisfied: smmap<6,>=3.0.1 in /Users/mak/miniforge3/lib/python3.12/site-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==3.5.1->mlflow) (5.0.2)\r\n",
                  "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/mak/miniforge3/lib/python3.12/site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.5.1->mlflow) (0.4.2)\r\n",
                  "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/mak/miniforge3/lib/python3.12/site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.5.1->mlflow) (4.9.1)\r\n",
                  "Requirement already satisfied: graphql-core<3.3,>=3.1 in /Users/mak/miniforge3/lib/python3.12/site-packages (from graphene<4->mlflow) (3.2.7)\r\n",
                  "Requirement already satisfied: graphql-relay<3.3,>=3.1 in /Users/mak/miniforge3/lib/python3.12/site-packages (from graphene<4->mlflow) (3.2.0)\r\n",
                  "Requirement already satisfied: python-dateutil<3,>=2.7.0 in /Users/mak/miniforge3/lib/python3.12/site-packages (from graphene<4->mlflow) (2.9.0.post0)\r\n"
               ]
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Requirement already satisfied: zipp>=3.20 in /Users/mak/miniforge3/lib/python3.12/site-packages (from importlib_metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==3.5.1->mlflow) (3.23.0)\r\n",
                  "Requirement already satisfied: contourpy>=1.0.1 in /Users/mak/miniforge3/lib/python3.12/site-packages (from matplotlib<4->mlflow) (1.3.3)\r\n",
                  "Requirement already satisfied: cycler>=0.10 in /Users/mak/miniforge3/lib/python3.12/site-packages (from matplotlib<4->mlflow) (0.12.1)\r\n",
                  "Requirement already satisfied: fonttools>=4.22.0 in /Users/mak/miniforge3/lib/python3.12/site-packages (from matplotlib<4->mlflow) (4.60.1)\r\n",
                  "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/mak/miniforge3/lib/python3.12/site-packages (from matplotlib<4->mlflow) (1.4.9)\r\n",
                  "Requirement already satisfied: pillow>=8 in /Users/mak/miniforge3/lib/python3.12/site-packages (from matplotlib<4->mlflow) (11.3.0)\r\n",
                  "Requirement already satisfied: pyparsing>=2.3.1 in /Users/mak/miniforge3/lib/python3.12/site-packages (from matplotlib<4->mlflow) (3.2.5)\r\n",
                  "Requirement already satisfied: opentelemetry-semantic-conventions==0.59b0 in /Users/mak/miniforge3/lib/python3.12/site-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==3.5.1->mlflow) (0.59b0)\r\n",
                  "Requirement already satisfied: pytz>=2020.1 in /Users/mak/miniforge3/lib/python3.12/site-packages (from pandas<3->mlflow) (2025.2)\r\n",
                  "Requirement already satisfied: tzdata>=2022.7 in /Users/mak/miniforge3/lib/python3.12/site-packages (from pandas<3->mlflow) (2025.2)\r\n",
                  "Requirement already satisfied: annotated-types>=0.6.0 in /Users/mak/miniforge3/lib/python3.12/site-packages (from pydantic<3,>=1.10.8->mlflow-skinny==3.5.1->mlflow) (0.7.0)\r\n",
                  "Requirement already satisfied: pydantic-core==2.33.2 in /Users/mak/miniforge3/lib/python3.12/site-packages (from pydantic<3,>=1.10.8->mlflow-skinny==3.5.1->mlflow) (2.33.2)\r\n",
                  "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/mak/miniforge3/lib/python3.12/site-packages (from pydantic<3,>=1.10.8->mlflow-skinny==3.5.1->mlflow) (0.4.2)\r\n",
                  "Requirement already satisfied: six>=1.5 in /Users/mak/miniforge3/lib/python3.12/site-packages (from python-dateutil<3,>=2.7.0->graphene<4->mlflow) (1.17.0)\r\n",
                  "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/mak/miniforge3/lib/python3.12/site-packages (from requests<3,>=2.17.3->mlflow-skinny==3.5.1->mlflow) (3.4.2)\r\n",
                  "Requirement already satisfied: idna<4,>=2.5 in /Users/mak/miniforge3/lib/python3.12/site-packages (from requests<3,>=2.17.3->mlflow-skinny==3.5.1->mlflow) (3.10)\r\n",
                  "Requirement already satisfied: certifi>=2017.4.17 in /Users/mak/miniforge3/lib/python3.12/site-packages (from requests<3,>=2.17.3->mlflow-skinny==3.5.1->mlflow) (2025.10.5)\r\n",
                  "Requirement already satisfied: pyasn1>=0.1.3 in /Users/mak/miniforge3/lib/python3.12/site-packages (from rsa<5,>=3.1.4->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.5.1->mlflow) (0.6.1)\r\n",
                  "Requirement already satisfied: joblib>=1.2.0 in /Users/mak/miniforge3/lib/python3.12/site-packages (from scikit-learn<2->mlflow) (1.5.2)\r\n",
                  "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/mak/miniforge3/lib/python3.12/site-packages (from scikit-learn<2->mlflow) (3.6.0)\r\n",
                  "Requirement already satisfied: anyio<5,>=3.6.2 in /Users/mak/miniforge3/lib/python3.12/site-packages (from starlette<0.50.0,>=0.40.0->fastapi<1->mlflow-skinny==3.5.1->mlflow) (4.11.0)\r\n",
                  "Requirement already satisfied: sniffio>=1.1 in /Users/mak/miniforge3/lib/python3.12/site-packages (from anyio<5,>=3.6.2->starlette<0.50.0,>=0.40.0->fastapi<1->mlflow-skinny==3.5.1->mlflow) (1.3.1)\r\n",
                  "Requirement already satisfied: h11>=0.8 in /Users/mak/miniforge3/lib/python3.12/site-packages (from uvicorn<1->mlflow-skinny==3.5.1->mlflow) (0.16.0)\r\n",
                  "Requirement already satisfied: colorlog in /Users/mak/miniforge3/lib/python3.12/site-packages (from optuna) (6.10.1)\r\n"
               ]
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Requirement already satisfied: tqdm in /Users/mak/miniforge3/lib/python3.12/site-packages (from optuna) (4.67.1)\r\n",
                  "Requirement already satisfied: pycparser in /Users/mak/miniforge3/lib/python3.12/site-packages (from cffi>=2.0.0->cryptography<47,>=43.0.0->mlflow) (2.22)\r\n"
               ]
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Note: you may need to restart the kernel to use updated packages.\n"
               ]
            }
         ],
         "source": [
            "%pip install mlflow optuna"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 4,
         "id": "a1e21f93",
         "metadata": {
            "execution": {
               "iopub.execute_input": "2025-11-05T05:03:53.496890Z",
               "iopub.status.busy": "2025-11-05T05:03:53.496809Z",
               "iopub.status.idle": "2025-11-05T05:03:55.239983Z",
               "shell.execute_reply": "2025-11-05T05:03:55.239709Z"
            }
         },
         "outputs": [
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  "/Users/mak/miniforge3/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
                  "  from .autonotebook import tqdm as notebook_tqdm\n"
               ]
            },
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  "2025/11/05 00:03:55 INFO mlflow.tracking.fluent: Experiment with name 'ames-housing-price-prediction' does not exist. Creating a new experiment.\n"
               ]
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Loading data...\n",
                  "Train shape: (1460, 81)\n",
                  "Test shape: (1459, 80)\n"
               ]
            }
         ],
         "source": [
            "import pandas as pd\n",
            "import numpy as np\n",
            "from sklearn.model_selection import train_test_split, cross_val_score\n",
            "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
            "import mlflow\n",
            "import joblib\n",
            "import optuna\n",
            "import xgboost as xgb\n",
            "from pathlib import Path\n",
            "\n",
            "# import custom transformers\n",
            "import os, sys\n",
            "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
            "if project_root not in sys.path:\n",
            "    sys.path.append(project_root)\n",
            "from models.custom_transformers import FeatureEngineer, LogTransformer\n",
            "\n",
            "# Configure MLflow\n",
            "# mlflow.set_tracking_uri(\"http://localhost:8000\")\n",
            "EXPERIMENT_NAME = \"ames-housing-price-prediction\"\n",
            "mlflow.set_experiment(EXPERIMENT_NAME)\n",
            "\n",
            "# Load the preprocessor\n",
            "# if these errors out, try running phase1_eda.ipynb first\n",
            "models_dir = \"../models\"\n",
            "feature_preprocessor = joblib.load(f'{models_dir}/feature_preprocessor.joblib')\n",
            "target_transformer = joblib.load(f'{models_dir}/target_transformer.joblib')\n",
            "\n",
            "print(\"Loading data...\")\n",
            "train_data = pd.read_csv('../data/house-prices-advanced-regression-techniques/train.csv')\n",
            "test_data = pd.read_csv('../data/house-prices-advanced-regression-techniques/test.csv')\n",
            "print(\"Train shape:\", train_data.shape)\n",
            "print(\"Test shape:\", test_data.shape)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 5,
         "id": "c6e50cb6",
         "metadata": {
            "execution": {
               "iopub.execute_input": "2025-11-05T05:03:55.241123Z",
               "iopub.status.busy": "2025-11-05T05:03:55.241050Z",
               "iopub.status.idle": "2025-11-05T05:03:55.257211Z",
               "shell.execute_reply": "2025-11-05T05:03:55.257005Z"
            }
         },
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Applying preprocessing pipeline...\n",
                  "X_train shape: (1168, 242)\n",
                  "X_val shape: (292, 242)\n"
               ]
            }
         ],
         "source": [
            "X = train_data.drop('SalePrice', axis=1)\n",
            "y = train_data['SalePrice']\n",
            "\n",
            "# apply pipelines/transformations\n",
            "X_processed = feature_preprocessor.transform(X)\n",
            "y_processed = target_transformer.transform(y)\n",
            "\n",
            "# Split data into train and validation sets\n",
            "# use _val to prevent confusion between the test dataset\n",
            "X_train, X_val, y_train, y_val = train_test_split(\n",
            "    X_processed, y_processed, \n",
            "    test_size=0.2, \n",
            "    random_state=42\n",
            ")\n",
            "\n",
            "# Apply preprocessing\n",
            "print(\"Applying preprocessing pipeline...\")\n",
            "print(\"X_train shape:\", X_train.shape)\n",
            "print(\"X_val shape:\", X_val.shape)"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "8329ebd4",
         "metadata": {},
         "source": [
            "## Baseline Model Development\n",
            "\n",
            "Let's start with a simple baseline model using XGBoost with default parameters. This will give us a reference point for further improvements."
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 6,
         "id": "091c1cbd",
         "metadata": {
            "execution": {
               "iopub.execute_input": "2025-11-05T05:03:55.258306Z",
               "iopub.status.busy": "2025-11-05T05:03:55.258245Z",
               "iopub.status.idle": "2025-11-05T05:03:55.259828Z",
               "shell.execute_reply": "2025-11-05T05:03:55.259649Z"
            }
         },
         "outputs": [],
         "source": [
            "def evaluate_model(model, X, y, prefix=''):\n",
            "    y_pred = model.predict(X)\n",
            "    rmse = np.sqrt(mean_squared_error(y, y_pred))\n",
            "    mae = mean_absolute_error(y, y_pred)\n",
            "    r2 = r2_score(y, y_pred)\n",
            "    \n",
            "    return {\n",
            "        f'{prefix}rmse': rmse,\n",
            "        f'{prefix}mae': mae,\n",
            "        f'{prefix}r2': r2\n",
            "    }"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 7,
         "id": "31a91ddf",
         "metadata": {
            "execution": {
               "iopub.execute_input": "2025-11-05T05:03:55.260760Z",
               "iopub.status.busy": "2025-11-05T05:03:55.260707Z",
               "iopub.status.idle": "2025-11-05T05:03:57.449381Z",
               "shell.execute_reply": "2025-11-05T05:03:57.449178Z"
            }
         },
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "[0]\tvalidation_0-rmse:0.33810\n"
               ]
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "[99]\tvalidation_0-rmse:0.15271\n"
               ]
            },
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  "2025/11/04 17:50:37 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
                  "/Users/nic/git/AmesHousingPredictor/.venv/lib/python3.10/site-packages/xgboost/sklearn.py:1115: UserWarning: [17:50:38] WARNING: /Users/runner/work/xgboost/xgboost/src/c_api/c_api.cc:1575: Saving model in the UBJSON format as default.  You can use a file extension: `json` or `ubj` to choose between formats.\n",
                  "  self.get_booster().save_model(fname)\n",
                  "2025/11/04 17:50:40 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
                  "\u001b[31m2025/11/04 17:50:40 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
               ]
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "\n",
                  "Training Metrics:\n",
                  "train_rmse: 0.0076\n",
                  "train_mae: 0.0055\n",
                  "train_r2: 0.9996\n",
                  "\n",
                  "Validation Metrics:\n",
                  "val_rmse: 0.1527\n",
                  "val_mae: 0.1064\n",
                  "val_r2: 0.8750\n",
                  "üèÉ View run xgboost-baseline at: http://localhost:8000/#/experiments/1/runs/802977bc39af45ddbd8e554593769deb\n",
                  "üß™ View experiment at: http://localhost:8000/#/experiments/1\n",
                  "\n",
                  "Baseline model saved to ../models/baseline_xgboost.joblib\n"
               ]
            }
         ],
         "source": [
            "# for training baseline XGBoost model\n",
            "with mlflow.start_run(run_name=\"xgboost-baseline\"):\n",
            "    # create model with default parameters\n",
            "    model = xgb.XGBRegressor(\n",
            "        random_state=42,\n",
            "        n_jobs=-1\n",
            "    )\n",
            "    \n",
            "    # train model\n",
            "    model.fit(\n",
            "        X_train, \n",
            "        y_train,\n",
            "        eval_set=[(X_val, y_val)],\n",
            "        verbose=100\n",
            "    )\n",
            "    \n",
            "    train_metrics = evaluate_model(model, X_train, y_train, prefix='train_')\n",
            "    val_metrics = evaluate_model(model, X_val, y_val, prefix='val_')\n",
            "    \n",
            "    mlflow.log_params(model.get_params())\n",
            "    mlflow.log_metrics({**train_metrics, **val_metrics})\n",
            "    mlflow.xgboost.log_model(model, \"model\")\n",
            "    \n",
            "    print(\"\\nTraining Metrics:\")\n",
            "    for metric, value in train_metrics.items():\n",
            "        print(f\"{metric}: {value:.4f}\")\n",
            "    \n",
            "    print(\"\\nValidation Metrics:\")\n",
            "    for metric, value in val_metrics.items():\n",
            "        print(f\"{metric}: {value:.4f}\")\n",
            "\n",
            "# Save the baseline model\n",
            "joblib.dump(model, f'{models_dir}/baseline_xgboost.joblib')\n",
            "print(f\"\\nBaseline model saved to {models_dir}/baseline_xgboost.joblib\")"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "a0d4956c",
         "metadata": {},
         "source": [
            "## Hyperparameter Optimization with Optuna\n",
            "\n",
            "Now that we have a baseline model, let's use Optuna to find better hyperparameters for our XGBoost model. We'll define an objective function that Optuna will optimize using cross-validation scores."
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 8,
         "id": "72bf2030",
         "metadata": {
            "execution": {
               "iopub.execute_input": "2025-11-05T05:03:57.450533Z",
               "iopub.status.busy": "2025-11-05T05:03:57.450445Z",
               "iopub.status.idle": "2025-11-05T05:04:23.603663Z",
               "shell.execute_reply": "2025-11-05T05:04:23.603294Z"
            }
         },
         "outputs": [
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  "[I 2025-11-04 17:50:40,988] A new study created in memory with name: no-name-16d042df-d7fc-473d-813d-947a4dd438a1\n",
                  "Best trial: 47. Best value: 0.124093: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [00:30<00:00,  1.66it/s]"
               ]
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Best trial:\n",
                  "  Value:  0.12409305778478182\n",
                  "  Params: \n",
                  "    max_depth: 3\n",
                  "    learning_rate: 0.03308285170291822\n",
                  "    n_estimators: 834\n",
                  "    min_child_weight: 4\n",
                  "    subsample: 0.7286386786349668\n",
                  "    colsample_bytree: 0.6201182915351288\n",
                  "    reg_alpha: 1.3640537686252489e-07\n",
                  "    reg_lambda: 2.3734191995955346e-08\n"
               ]
            },
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  "\n"
               ]
            }
         ],
         "source": [
            "# objective function for Optuna\n",
            "def objective(trial):\n",
            "    params = {\n",
            "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
            "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1, log=True),\n",
            "        'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
            "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 7),\n",
            "        'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
            "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n",
            "        'reg_alpha': trial.suggest_float('reg_alpha', 1e-8, 1.0, log=True),\n",
            "        'reg_lambda': trial.suggest_float('reg_lambda', 1e-8, 1.0, log=True),\n",
            "        'random_state': 42\n",
            "    }\n",
            "    \n",
            "    # get model with suggested parameters\n",
            "    model = xgb.XGBRegressor(**params)\n",
            "    \n",
            "    # cross-validation\n",
            "    cv_scores = cross_val_score(\n",
            "        model, \n",
            "        X_train, \n",
            "        y_train, \n",
            "        cv=5, \n",
            "        scoring='neg_root_mean_squared_error',\n",
            "        n_jobs=-1\n",
            "    )\n",
            "    \n",
            "    # mean negative RMSE (Optuna minimizes objective)\n",
            "    return -cv_scores.mean()\n",
            "\n",
            "# Create and run Optuna study\n",
            "study = optuna.create_study(direction='minimize')\n",
            "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
            "study.optimize(objective, n_trials=50, show_progress_bar=True)\n",
            "\n",
            "print(\"Best trial:\")\n",
            "trial = study.best_trial\n",
            "\n",
            "print(\"  Value: \", trial.value)\n",
            "print(\"  Params: \")\n",
            "for key, value in trial.params.items():\n",
            "    print(\"    {}: {}\".format(key, value))"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 9,
         "id": "969dbd2d",
         "metadata": {
            "execution": {
               "iopub.execute_input": "2025-11-05T05:04:23.605396Z",
               "iopub.status.busy": "2025-11-05T05:04:23.605292Z",
               "iopub.status.idle": "2025-11-05T05:04:26.139825Z",
               "shell.execute_reply": "2025-11-05T05:04:26.139620Z"
            }
         },
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "[0]\tvalidation_0-rmse:0.42364\n",
                  "[100]\tvalidation_0-rmse:0.15476\n",
                  "[200]\tvalidation_0-rmse:0.13882\n",
                  "[300]\tvalidation_0-rmse:0.13435\n",
                  "[400]\tvalidation_0-rmse:0.13270\n",
                  "[500]\tvalidation_0-rmse:0.13262\n",
                  "[600]\tvalidation_0-rmse:0.13259\n",
                  "[700]\tvalidation_0-rmse:0.13275\n",
                  "[800]\tvalidation_0-rmse:0.13326\n",
                  "[833]\tvalidation_0-rmse:0.13342\n"
               ]
            },
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  "/Users/nic/git/AmesHousingPredictor/.venv/lib/python3.10/site-packages/xgboost/sklearn.py:1115: UserWarning: [17:51:12] WARNING: /Users/runner/work/xgboost/xgboost/src/c_api/c_api.cc:1575: Saving model in the UBJSON format as default.  You can use a file extension: `json` or `ubj` to choose between formats.\n",
                  "  self.get_booster().save_model(fname)\n",
                  "2025/11/04 17:51:14 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
                  "\u001b[31m2025/11/04 17:51:14 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
               ]
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "\n",
                  "Training Metrics:\n",
                  "train_rmse: 0.0574\n",
                  "train_mae: 0.0420\n",
                  "train_r2: 0.9784\n",
                  "\n",
                  "Validation Metrics:\n",
                  "val_rmse: 0.1334\n",
                  "val_mae: 0.0894\n",
                  "val_r2: 0.9046\n",
                  "üèÉ View run xgboost-optimized at: http://localhost:8000/#/experiments/1/runs/5f17ca27d7dd4c32a242aa61282e04c9\n",
                  "üß™ View experiment at: http://localhost:8000/#/experiments/1\n",
                  "\n",
                  "Optimized model saved to ../models/optimized_xgboost.joblib\n"
               ]
            }
         ],
         "source": [
            "# for training the optimized model\n",
            "with mlflow.start_run(run_name=\"xgboost-optimized\"):\n",
            "    # get model with best parameters\n",
            "    best_params = study.best_params\n",
            "    best_params['random_state'] = 42\n",
            "    model = xgb.XGBRegressor(**best_params)\n",
            "    \n",
            "    model.fit(\n",
            "        X_train, \n",
            "        y_train,\n",
            "        eval_set=[(X_val, y_val)],\n",
            "        verbose=100\n",
            "    )\n",
            "    \n",
            "    train_metrics = evaluate_model(model, X_train, y_train, prefix='train_')\n",
            "    val_metrics = evaluate_model(model, X_val, y_val, prefix='val_')\n",
            "    \n",
            "    mlflow.log_params(model.get_params())\n",
            "    mlflow.log_metrics({**train_metrics, **val_metrics})\n",
            "    mlflow.xgboost.log_model(model, name=\"model\")\n",
            "    \n",
            "    print(\"\\nTraining Metrics:\")\n",
            "    for metric, value in train_metrics.items():\n",
            "        print(f\"{metric}: {value:.4f}\")\n",
            "    \n",
            "    print(\"\\nValidation Metrics:\")\n",
            "    for metric, value in val_metrics.items():\n",
            "        print(f\"{metric}: {value:.4f}\")\n",
            "\n",
            "# save optimized model\n",
            "joblib.dump(model, '../models/optimized_xgboost.joblib')\n",
            "print(\"\\nOptimized model saved to ../models/optimized_xgboost.joblib\")"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "baa358f3",
         "metadata": {},
         "source": [
            "## Model Comparison\n",
            "\n",
            "Let's compare the performance of our baseline and optimized models to see the improvement from hyperparameter optimization."
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 10,
         "id": "049b2257",
         "metadata": {
            "execution": {
               "iopub.execute_input": "2025-11-05T05:04:26.140932Z",
               "iopub.status.busy": "2025-11-05T05:04:26.140856Z",
               "iopub.status.idle": "2025-11-05T05:04:26.146427Z",
               "shell.execute_reply": "2025-11-05T05:04:26.146236Z"
            }
         },
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Baseline Model Metrics:\n",
                  "rmse: 0.1527\n",
                  "mae: 0.1064\n",
                  "r2: 0.8750\n",
                  "\n",
                  "Optimized Model Metrics:\n",
                  "rmse: 0.1334\n",
                  "mae: 0.0894\n",
                  "r2: 0.9046\n",
                  "\n",
                  "RMSE Improvement: 12.63%\n"
               ]
            }
         ],
         "source": [
            "baseline_model = joblib.load('../models/baseline_xgboost.joblib')\n",
            "\n",
            "# compare models on validation set\n",
            "baseline_metrics = evaluate_model(baseline_model, X_val, y_val)\n",
            "optimized_metrics = evaluate_model(model, X_val, y_val)\n",
            "\n",
            "print(\"Baseline Model Metrics:\")\n",
            "for metric, value in baseline_metrics.items():\n",
            "    print(f\"{metric}: {value:.4f}\")\n",
            "\n",
            "print(\"\\nOptimized Model Metrics:\")\n",
            "for metric, value in optimized_metrics.items():\n",
            "    print(f\"{metric}: {value:.4f}\")\n",
            "\n",
            "improvement = (baseline_metrics['rmse'] - optimized_metrics['rmse']) / baseline_metrics['rmse'] * 100\n",
            "print(f\"\\nRMSE Improvement: {improvement:.2f}%\")"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 11,
         "id": "d8a43acb",
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Saved full pipeline to ../models/full_pipeline.joblib\n",
                  "Example prediction (SalePrice): [121776.33]\n"
               ]
            }
         ],
         "source": [
            "# Compose the preprocessor and trained model into a single sklearn-compatible object\n",
            "# and use TransformedTargetRegressor so the target transformer is applied automatically.\n",
            "from pathlib import Path\n",
            "from sklearn.pipeline import Pipeline\n",
            "from sklearn.compose import TransformedTargetRegressor\n",
            "\n",
            "# Build an sklearn Pipeline that first applies the feature preprocessor then the model.\n",
            "# Note: feature_preprocessor and model are expected to be already fitted objects.\n",
            "skl_pipeline = Pipeline([\n",
            "    (\"preprocessor\", feature_preprocessor),\n",
            "    (\"regressor\", model),\n",
            "])\n",
            "\n",
            "# Wrap with TransformedTargetRegressor so predictions are returned on the original scale.\n",
            "full_pipeline = TransformedTargetRegressor(regressor=skl_pipeline, transformer=target_transformer)\n",
            "full_pipeline.fit(X, y)\n",
            "\n",
            "# Save the composed object (sklearn pipeline or fallback wrapper)\n",
            "models_path = Path(models_dir)\n",
            "models_path.mkdir(parents=True, exist_ok=True)\n",
            "joblib.dump(full_pipeline, models_path / \"full_pipeline.joblib\")\n",
            "print(f\"Saved full pipeline to {models_path / 'full_pipeline.joblib'}\")\n",
            "\n",
            "# Example: predict on a single row from the test set (keeps original columns)\n",
            "example_row = test_data.iloc[[0]]  # DataFrame with one row\n",
            "pred = full_pipeline.predict(example_row)\n",
            "print(\"Example prediction (SalePrice):\", pred)\n"
         ]
      }
   ],
   "metadata": {
      "kernelspec": {
         "display_name": "AmesHousingPredictor",
         "language": "python",
         "name": "python3"
      },
      "language_info": {
         "codemirror_mode": {
            "name": "ipython",
            "version": 3
         },
         "file_extension": ".py",
         "mimetype": "text/x-python",
         "name": "python",
         "nbconvert_exporter": "python",
         "pygments_lexer": "ipython3",
         "version": "3.12.11"
      }
   },
   "nbformat": 4,
   "nbformat_minor": 5
}