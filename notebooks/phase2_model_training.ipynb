{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "352eafe6",
   "metadata": {},
   "source": [
    "# Phase 2: Model Training and Experimentation\n",
    "\n",
    "This notebook will focus on training and optimizing our model. Our objectives include\n",
    "1. Experiment tracking with MLflow\n",
    "2. Cross-validation\n",
    "3. Hyperparameter optimization\n",
    "4. Model evaluation and selection\n",
    "5. Model versioning and registration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e963f08b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-05T05:03:52.711998Z",
     "iopub.status.busy": "2025-11-05T05:03:52.711754Z",
     "iopub.status.idle": "2025-11-05T05:03:53.495768Z",
     "shell.execute_reply": "2025-11-05T05:03:53.495471Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/nic/git/AmesHousingPredictor/.venv/bin/python: No module named pip\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# ignore this: required for run_notebooks.sh\n",
    "%pip install mlflow optuna --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a1e21f93",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-05T05:03:53.496890Z",
     "iopub.status.busy": "2025-11-05T05:03:53.496809Z",
     "iopub.status.idle": "2025-11-05T05:03:55.239983Z",
     "shell.execute_reply": "2025-11-05T05:03:55.239709Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Train shape: (1460, 80)\n",
      "Test shape: (1459, 79)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import joblib\n",
    "import optuna\n",
    "import xgboost as xgb\n",
    "\n",
    "print(\"Loading data...\")\n",
    "import ames_notebooks\n",
    "from app.data_ingestion.read_data import DataReader\n",
    "\n",
    "reader = DataReader()\n",
    "train_data, test_data = reader.load_train_test()\n",
    "print(\"Train shape:\", train_data.shape)\n",
    "print(\"Test shape:\", test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d2f21cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get preprocessing pipeline\n",
    "from app.pipelines.preprocessing import get_fitted_pipelines\n",
    "feature_preprocessor, target_transformer = get_fitted_pipelines(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c6e50cb6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-05T05:03:55.241123Z",
     "iopub.status.busy": "2025-11-05T05:03:55.241050Z",
     "iopub.status.idle": "2025-11-05T05:03:55.257211Z",
     "shell.execute_reply": "2025-11-05T05:03:55.257005Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying preprocessing pipeline...\n",
      "X_train shape: (1168, 241)\n",
      "X_val shape: (292, 241)\n"
     ]
    }
   ],
   "source": [
    "X = train_data.drop('SalePrice', axis=1)\n",
    "y = train_data['SalePrice']\n",
    "\n",
    "# apply pipelines/transformations\n",
    "X_processed = feature_preprocessor.transform(X)\n",
    "y_processed = target_transformer.transform(y)\n",
    "\n",
    "# Split data into train and validation sets\n",
    "# use _val to prevent confusion between the test dataset\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_processed, y_processed, \n",
    "    test_size=0.2, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Apply preprocessing\n",
    "print(\"Applying preprocessing pipeline...\")\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_val shape:\", X_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8329ebd4",
   "metadata": {},
   "source": [
    "## Baseline Model Development\n",
    "\n",
    "Let's start with a simple baseline model using XGBoost with default parameters. This will give us a reference point for further improvements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "091c1cbd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-05T05:03:55.258306Z",
     "iopub.status.busy": "2025-11-05T05:03:55.258245Z",
     "iopub.status.idle": "2025-11-05T05:03:55.259828Z",
     "shell.execute_reply": "2025-11-05T05:03:55.259649Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_model(model, X, y, prefix=''):\n",
    "    y_pred = model.predict(X)\n",
    "    rmse = np.sqrt(mean_squared_error(y, y_pred))\n",
    "    mae = mean_absolute_error(y, y_pred)\n",
    "    r2 = r2_score(y, y_pred)\n",
    "    \n",
    "    return {\n",
    "        f'{prefix}rmse': rmse,\n",
    "        f'{prefix}mae': mae,\n",
    "        f'{prefix}r2': r2\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0b6fadfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/12 10:50:05 INFO mlflow.tracking.fluent: Experiment with name 'ames-housing-pricing-experiment' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='/Users/nic/git/AmesHousingPredictor/notebooks/mlruns/928459568205706713', creation_time=1762962605946, experiment_id='928459568205706713', last_update_time=1762962605946, lifecycle_stage='active', name='ames-housing-pricing-experiment', tags={}>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Configure MLflow\n",
    "import mlflow\n",
    "from app.config.settings import settings\n",
    "# mlflow.set_tracking_uri(\"http://localhost:8000\")\n",
    "mlflow.set_tracking_uri(\"./mlruns\")\n",
    "mlflow.set_experiment(settings.MLFLOW_EXPERIMENT_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "31a91ddf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-05T05:03:55.260760Z",
     "iopub.status.busy": "2025-11-05T05:03:55.260707Z",
     "iopub.status.idle": "2025-11-05T05:03:57.449381Z",
     "shell.execute_reply": "2025-11-05T05:03:57.449178Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-rmse:0.33887\n",
      "[99]\tvalidation_0-rmse:0.14973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/12 10:50:15 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "/Users/nic/git/AmesHousingPredictor/.venv/lib/python3.10/site-packages/xgboost/sklearn.py:1115: UserWarning: [10:50:15] WARNING: /Users/runner/work/xgboost/xgboost/src/c_api/c_api.cc:1575: Saving model in the UBJSON format as default.  You can use a file extension: `json` or `ubj` to choose between formats.\n",
      "  self.get_booster().save_model(fname)\n",
      "2025/11/12 10:50:18 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "\u001b[31m2025/11/12 10:50:18 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Metrics:\n",
      "train_rmse: 0.0078\n",
      "train_mae: 0.0054\n",
      "train_r2: 0.9996\n",
      "\n",
      "Validation Metrics:\n",
      "val_rmse: 0.1497\n",
      "val_mae: 0.1038\n",
      "val_r2: 0.8799\n",
      "\n",
      "Baseline model saved to ../models/baseline_xgboost.joblib\n"
     ]
    }
   ],
   "source": [
    "# for training baseline XGBoost model\n",
    "with mlflow.start_run(run_name=\"xgboost-baseline\"):\n",
    "    # create model with default parameters\n",
    "    model = xgb.XGBRegressor(\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    # train model\n",
    "    model.fit(\n",
    "        X_train, \n",
    "        y_train,\n",
    "        eval_set=[(X_val, y_val)],\n",
    "        verbose=100\n",
    "    )\n",
    "    \n",
    "    train_metrics = evaluate_model(model, X_train, y_train, prefix='train_')\n",
    "    val_metrics = evaluate_model(model, X_val, y_val, prefix='val_')\n",
    "    \n",
    "    mlflow.log_params(model.get_params())\n",
    "    mlflow.log_metrics({**train_metrics, **val_metrics})\n",
    "    mlflow.xgboost.log_model(model, \"model\")\n",
    "    \n",
    "    print(\"\\nTraining Metrics:\")\n",
    "    for metric, value in train_metrics.items():\n",
    "        print(f\"{metric}: {value:.4f}\")\n",
    "    \n",
    "    print(\"\\nValidation Metrics:\")\n",
    "    for metric, value in val_metrics.items():\n",
    "        print(f\"{metric}: {value:.4f}\")\n",
    "\n",
    "# Save the baseline model\n",
    "joblib.dump(model, '../models/baseline_xgboost.joblib')\n",
    "print(\"\\nBaseline model saved to ../models/baseline_xgboost.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d4956c",
   "metadata": {},
   "source": [
    "## Hyperparameter Optimization with Optuna\n",
    "\n",
    "Now that we have a baseline model, let's use Optuna to find better hyperparameters for our XGBoost model. We'll define an objective function that Optuna will optimize using cross-validation scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "72bf2030",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-05T05:03:57.450533Z",
     "iopub.status.busy": "2025-11-05T05:03:57.450445Z",
     "iopub.status.idle": "2025-11-05T05:04:23.603663Z",
     "shell.execute_reply": "2025-11-05T05:04:23.603294Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-12 10:50:18,388] A new study created in memory with name: no-name-ea0e4606-a070-4f44-85f2-0daa33a66f0a\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86abdcb85e9241debd15d79fc6704822",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial:\n",
      "  Value:  0.12477794471857348\n",
      "  Params: \n",
      "    max_depth: 3\n",
      "    learning_rate: 0.02709994303786845\n",
      "    n_estimators: 814\n",
      "    min_child_weight: 1\n",
      "    subsample: 0.9300191782543125\n",
      "    colsample_bytree: 0.648701250908197\n",
      "    reg_alpha: 3.865348574052837e-08\n",
      "    reg_lambda: 7.325087400964345e-05\n"
     ]
    }
   ],
   "source": [
    "# objective function for Optuna\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1, log=True),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 7),\n",
    "        'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 1e-8, 1.0, log=True),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 1e-8, 1.0, log=True),\n",
    "        'random_state': 42\n",
    "    }\n",
    "    \n",
    "    # get model with suggested parameters\n",
    "    model = xgb.XGBRegressor(**params)\n",
    "    \n",
    "    # cross-validation\n",
    "    cv_scores = cross_val_score(\n",
    "        model, \n",
    "        X_train, \n",
    "        y_train, \n",
    "        cv=5, \n",
    "        scoring='neg_root_mean_squared_error',\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    # mean negative RMSE (Optuna minimizes objective)\n",
    "    return -cv_scores.mean()\n",
    "\n",
    "# Create and run Optuna study\n",
    "study = optuna.create_study(direction='minimize')\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "study.optimize(objective, n_trials=50, show_progress_bar=True)\n",
    "\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print(\"  Value: \", trial.value)\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969dbd2d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-05T05:04:23.605396Z",
     "iopub.status.busy": "2025-11-05T05:04:23.605292Z",
     "iopub.status.idle": "2025-11-05T05:04:26.139825Z",
     "shell.execute_reply": "2025-11-05T05:04:26.139620Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-rmse:0.42494\n",
      "[100]\tvalidation_0-rmse:0.16594\n",
      "[200]\tvalidation_0-rmse:0.14449\n",
      "[300]\tvalidation_0-rmse:0.13807\n",
      "[400]\tvalidation_0-rmse:0.13585\n",
      "[500]\tvalidation_0-rmse:0.13532\n",
      "[600]\tvalidation_0-rmse:0.13497\n",
      "[700]\tvalidation_0-rmse:0.13508\n",
      "[800]\tvalidation_0-rmse:0.13477\n",
      "[813]\tvalidation_0-rmse:0.13480\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nic/git/AmesHousingPredictor/.venv/lib/python3.10/site-packages/xgboost/sklearn.py:1115: UserWarning: [10:50:52] WARNING: /Users/runner/work/xgboost/xgboost/src/c_api/c_api.cc:1575: Saving model in the UBJSON format as default.  You can use a file extension: `json` or `ubj` to choose between formats.\n",
      "  self.get_booster().save_model(fname)\n",
      "2025/11/12 10:50:54 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "\u001b[31m2025/11/12 10:50:54 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Metrics:\n",
      "train_rmse: 0.0591\n",
      "train_mae: 0.0451\n",
      "train_r2: 0.9771\n",
      "\n",
      "Validation Metrics:\n",
      "val_rmse: 0.1348\n",
      "val_mae: 0.0891\n",
      "val_r2: 0.9026\n",
      "\n",
      "Optimized model saved to ../models/optimized_xgboost.joblib\n"
     ]
    }
   ],
   "source": [
    "# for training the optimized model\n",
    "with mlflow.start_run(run_name=\"xgboost-optimized\"):\n",
    "    # get model with best parameters\n",
    "    best_params = study.best_params\n",
    "    best_params['random_state'] = 42\n",
    "    model = xgb.XGBRegressor(**best_params)\n",
    "    \n",
    "    model.fit(\n",
    "        X_train, \n",
    "        y_train,\n",
    "        eval_set=[(X_val, y_val)],\n",
    "        verbose=100\n",
    "    )\n",
    "\n",
    "    \n",
    "    train_metrics = evaluate_model(model, X_train, y_train, prefix='train_')\n",
    "    val_metrics = evaluate_model(model, X_val, y_val, prefix='val_')\n",
    "    \n",
    "    mlflow.log_params(model.get_params())\n",
    "    mlflow.log_metrics({**train_metrics, **val_metrics})\n",
    "    mlflow.xgboost.log_model(model, name=\"model\")\n",
    "    \n",
    "    print(\"\\nTraining Metrics:\")\n",
    "    for metric, value in train_metrics.items():\n",
    "        print(f\"{metric}: {value:.4f}\")\n",
    "    \n",
    "    print(\"\\nValidation Metrics:\")\n",
    "    for metric, value in val_metrics.items():\n",
    "        print(f\"{metric}: {value:.4f}\")\n",
    "\n",
    "# save optimized model\n",
    "joblib.dump(model, '../models/optimized_xgboost.joblib')\n",
    "print(\"\\nOptimized model saved to ../models/optimized_xgboost.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa358f3",
   "metadata": {},
   "source": [
    "## Model Comparison\n",
    "\n",
    "Let's compare the performance of our baseline and optimized models to see the improvement from hyperparameter optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "049b2257",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-05T05:04:26.140932Z",
     "iopub.status.busy": "2025-11-05T05:04:26.140856Z",
     "iopub.status.idle": "2025-11-05T05:04:26.146427Z",
     "shell.execute_reply": "2025-11-05T05:04:26.146236Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Model Metrics:\n",
      "rmse: 0.1497\n",
      "mae: 0.1038\n",
      "r2: 0.8799\n",
      "\n",
      "Optimized Model Metrics:\n",
      "rmse: 0.1348\n",
      "mae: 0.0891\n",
      "r2: 0.9026\n",
      "\n",
      "RMSE Improvement: 9.97%\n"
     ]
    }
   ],
   "source": [
    "baseline_model = joblib.load('../models/baseline_xgboost.joblib')\n",
    "\n",
    "# compare models on validation set\n",
    "baseline_metrics = evaluate_model(baseline_model, X_val, y_val)\n",
    "optimized_metrics = evaluate_model(model, X_val, y_val)\n",
    "\n",
    "print(\"Baseline Model Metrics:\")\n",
    "for metric, value in baseline_metrics.items():\n",
    "    print(f\"{metric}: {value:.4f}\")\n",
    "\n",
    "print(\"\\nOptimized Model Metrics:\")\n",
    "for metric, value in optimized_metrics.items():\n",
    "    print(f\"{metric}: {value:.4f}\")\n",
    "\n",
    "improvement = (baseline_metrics['rmse'] - optimized_metrics['rmse']) / baseline_metrics['rmse'] * 100\n",
    "print(f\"\\nRMSE Improvement: {improvement:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d8a43acb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved full pipeline to ../models/full_pipeline.joblib\n",
      "Example prediction (SalePrice): [120046.805]\n"
     ]
    }
   ],
   "source": [
    "# Compose the preprocessor and trained model into a single sklearn-compatible object\n",
    "# and use TransformedTargetRegressor so the target transformer is applied automatically.\n",
    "from pathlib import Path\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "\n",
    "# Build an sklearn Pipeline that first applies the feature preprocessor then the model.\n",
    "# Note: feature_preprocessor and model are expected to be already fitted objects.\n",
    "skl_pipeline = Pipeline([\n",
    "    (\"preprocessor\", feature_preprocessor),\n",
    "    (\"regressor\", model),\n",
    "])\n",
    "\n",
    "# Wrap with TransformedTargetRegressor so predictions are returned on the original scale.\n",
    "full_pipeline = TransformedTargetRegressor(regressor=skl_pipeline, transformer=target_transformer)\n",
    "full_pipeline.fit(X, y)\n",
    "\n",
    "# Save the composed object (sklearn pipeline or fallback wrapper)\n",
    "models_path = Path(\"../models\")\n",
    "models_path.mkdir(parents=True, exist_ok=True)\n",
    "joblib.dump(full_pipeline, models_path / \"full_pipeline.joblib\")\n",
    "print(f\"Saved full pipeline to {models_path / 'full_pipeline.joblib'}\")\n",
    "\n",
    "# Example: predict on a single row from the test set (keeps original columns)\n",
    "example_row = test_data.iloc[[0]]  # DataFrame with one row\n",
    "pred = full_pipeline.predict(example_row)\n",
    "print(\"Example prediction (SalePrice):\", pred)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AmesHousingPredictor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
