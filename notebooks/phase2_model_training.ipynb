{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "352eafe6",
   "metadata": {},
   "source": [
    "# Phase 2: Model Training and Experimentation\n",
    "\n",
    "This notebook will focus on training and optimizing our model. Our objectives include\n",
    "1. Experiment tracking with MLflow\n",
    "2. Cross-validation\n",
    "3. Hyperparameter optimization\n",
    "4. Model evaluation and selection\n",
    "5. Model versioning and registration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e963f08b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-20T14:05:56.682614Z",
     "start_time": "2025-11-20T14:05:54.310924Z"
    },
    "execution": {
     "iopub.execute_input": "2025-11-05T05:03:52.711998Z",
     "iopub.status.busy": "2025-11-05T05:03:52.711754Z",
     "iopub.status.idle": "2025-11-05T05:03:53.495768Z",
     "shell.execute_reply": "2025-11-05T05:03:53.495471Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/nic/git/AmesHousingPredictor/.venv/bin/python: No module named pip\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "/Users/nic/git/AmesHousingPredictor/.venv/bin/python: No module named pip\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# ignore this: required for run_notebooks.sh\n",
    "%pip install --upgrade pip --quiet\n",
    "%pip install mlflow optuna --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1e21f93",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-20T14:05:57.554037Z",
     "start_time": "2025-11-20T14:05:56.691871Z"
    },
    "execution": {
     "iopub.execute_input": "2025-11-05T05:03:53.496890Z",
     "iopub.status.busy": "2025-11-05T05:03:53.496809Z",
     "iopub.status.idle": "2025-11-05T05:03:55.239983Z",
     "shell.execute_reply": "2025-11-05T05:03:55.239709Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-11-21 11:48:34.457\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mapp.config.settings\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m29\u001b[0m - \u001b[34m\u001b[1mloaded settings: {\n",
      "    \"DATA_DIRECTORY\": \"data\",\n",
      "    \"RAW_DATA_DIRECTORY\": \"data/raw\",\n",
      "    \"PROCESSED_DATA_DIRECTORY\": \"data/processed\",\n",
      "    \"KAGGLE_COMPETITION\": \"house-prices-advanced-regression-techniques\",\n",
      "    \"KAGGLE_DOWNLOAD_PATH\": \"data/house-prices-advanced-regression-techniques.zip\",\n",
      "    \"PROD_MODEL_NAME\": \"prod\",\n",
      "    \"LOG_LEVEL\": \"INFO\",\n",
      "    \"LOG_FILE\": \"logs/app.log\",\n",
      "    \"MLFLOW_EXPERIMENT_NAME\": \"ames-housing-pricing-experiment\",\n",
      "    \"MLFLOW_TRACKING_URI\": \"http://127.0.0.1:8500\"\n",
      "}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Train shape: (1460, 80)\n",
      "Test shape: (1459, 79)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "import optuna\n",
    "import xgboost as xgb\n",
    "\n",
    "print(\"Loading data...\")\n",
    "import ames_notebooks\n",
    "from app.data_ingestion.read_data import DataReader\n",
    "\n",
    "reader = DataReader()\n",
    "train_data, test_data = reader.load_train_test()\n",
    "print(\"Train shape:\", train_data.shape)\n",
    "print(\"Test shape:\", test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d2f21cd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-20T14:05:57.705575Z",
     "start_time": "2025-11-20T14:05:57.557777Z"
    }
   },
   "outputs": [],
   "source": [
    "# get preprocessing pipeline\n",
    "from app.pipelines.preprocessing import get_fitted_pipelines\n",
    "feature_preprocessor, target_transformer = get_fitted_pipelines(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6e50cb6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-20T14:05:57.734974Z",
     "start_time": "2025-11-20T14:05:57.709989Z"
    },
    "execution": {
     "iopub.execute_input": "2025-11-05T05:03:55.241123Z",
     "iopub.status.busy": "2025-11-05T05:03:55.241050Z",
     "iopub.status.idle": "2025-11-05T05:03:55.257211Z",
     "shell.execute_reply": "2025-11-05T05:03:55.257005Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying preprocessing pipeline...\n",
      "X_train shape: (1168, 241)\n",
      "X_val shape: (292, 241)\n"
     ]
    }
   ],
   "source": [
    "X = train_data.drop('SalePrice', axis=1)\n",
    "y = train_data['SalePrice']\n",
    "\n",
    "# apply pipelines/transformations\n",
    "X_processed = feature_preprocessor.transform(X)\n",
    "y_processed = target_transformer.transform(y)\n",
    "\n",
    "# Split data into train and validation sets\n",
    "# use _val to prevent confusion between the test dataset\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_processed, y_processed, \n",
    "    test_size=0.2, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Apply preprocessing\n",
    "print(\"Applying preprocessing pipeline...\")\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_val shape:\", X_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8329ebd4",
   "metadata": {},
   "source": [
    "## Baseline Model Development\n",
    "\n",
    "Let's start with a simple baseline model using XGBoost with default parameters. This will give us a reference point for further improvements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bbd21bc3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-20T14:06:02.360166Z",
     "start_time": "2025-11-20T14:05:57.741156Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/21 11:48:41 INFO mlflow.tracking.fluent: Experiment with name 'ames-housing-pricing-experiment211125114838' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-rmse:0.33887\n",
      "[99]\tvalidation_0-rmse:0.14973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nic/git/AmesHousingPredictor/.venv/lib/python3.10/site-packages/xgboost/sklearn.py:1115: UserWarning: [11:48:47] WARNING: /Users/runner/work/xgboost/xgboost/src/c_api/c_api.cc:1575: Saving model in the UBJSON format as default.  You can use a file extension: `json` or `ubj` to choose between formats.\n",
      "  self.get_booster().save_model(fname)\n",
      "2025/11/21 11:48:50 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "/Users/nic/git/AmesHousingPredictor/.venv/lib/python3.10/site-packages/xgboost/sklearn.py:1124: UserWarning: [11:48:50] WARNING: /Users/runner/work/xgboost/xgboost/src/c_api/c_api.cc:1511: Unknown file format: `xgb`. Using UBJSON (`ubj`) as a guess.\n",
      "  self.get_booster().load_model(fname)\n",
      "Successfully registered model 'xgboost-baseline'.\n",
      "2025/11/21 11:48:59 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: xgboost-baseline, version 1\n",
      "Created version '1' of model 'xgboost-baseline'.\n",
      "\u001b[32m2025-11-21 11:49:00.487\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mapp.pipelines.training\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m64\u001b[0m - \u001b[1m\n",
      "Training Metrics:\u001b[0m\n",
      "\u001b[32m2025-11-21 11:49:00.487\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mapp.pipelines.training\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m66\u001b[0m - \u001b[1mtrain_rmse: 0.0078\u001b[0m\n",
      "\u001b[32m2025-11-21 11:49:00.488\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mapp.pipelines.training\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m66\u001b[0m - \u001b[1mtrain_mae: 0.0054\u001b[0m\n",
      "\u001b[32m2025-11-21 11:49:00.488\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mapp.pipelines.training\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m66\u001b[0m - \u001b[1mtrain_r2: 0.9996\u001b[0m\n",
      "\u001b[32m2025-11-21 11:49:00.489\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mapp.pipelines.training\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m68\u001b[0m - \u001b[1m\n",
      "Validation Metrics:\u001b[0m\n",
      "\u001b[32m2025-11-21 11:49:00.490\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mapp.pipelines.training\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m70\u001b[0m - \u001b[1mval_rmse: 0.1497\u001b[0m\n",
      "\u001b[32m2025-11-21 11:49:00.490\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mapp.pipelines.training\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m70\u001b[0m - \u001b[1mval_mae: 0.1038\u001b[0m\n",
      "\u001b[32m2025-11-21 11:49:00.491\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mapp.pipelines.training\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m70\u001b[0m - \u001b[1mval_r2: 0.8799\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run train-run-xgboost-baseline at: http://127.0.0.1:8500/#/experiments/4/runs/894fb9fcb34648709f91617b04acfabf\n",
      "üß™ View experiment at: http://127.0.0.1:8500/#/experiments/4\n",
      "\n",
      "Training Metrics:\n",
      "train_rmse: 0.0078\n",
      "train_mae: 0.0054\n",
      "train_r2: 0.9996\n",
      "\n",
      "Validation Metrics:\n",
      "val_rmse: 0.1497\n",
      "val_mae: 0.1038\n",
      "val_r2: 0.8799\n"
     ]
    }
   ],
   "source": [
    "from app.pipelines.training import XGBModelTrainer\n",
    "\n",
    "model = xgb.XGBRegressor(random_state=42, n_jobs=-1)\n",
    "\n",
    "trainer = XGBModelTrainer()\n",
    "baseline_model = trainer.train(model, \"xgboost-baseline\", X_train, y_train, X_val, y_val)\n",
    "\n",
    "print(\"\\nTraining Metrics:\")\n",
    "for metric, value in trainer.train_metrics.items():\n",
    "    print(f\"{metric}: {value:.4f}\")\n",
    "\n",
    "print(\"\\nValidation Metrics:\")\n",
    "for metric, value in trainer.val_metrics.items():\n",
    "    print(f\"{metric}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d4956c",
   "metadata": {},
   "source": [
    "## Hyperparameter Optimization with Optuna\n",
    "\n",
    "Now that we have a baseline model, let's use Optuna to find better hyperparameters for our XGBoost model. We'll define an objective function that Optuna will optimize using cross-validation scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72bf2030",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-20T14:06:33.382031Z",
     "start_time": "2025-11-20T14:06:02.373548Z"
    },
    "execution": {
     "iopub.execute_input": "2025-11-05T05:03:57.450533Z",
     "iopub.status.busy": "2025-11-05T05:03:57.450445Z",
     "iopub.status.idle": "2025-11-05T05:04:23.603663Z",
     "shell.execute_reply": "2025-11-05T05:04:23.603294Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-21 11:49:01,216] A new study created in memory with name: no-name-8c0817a7-2283-426e-9535-7df996b411c6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "865799d9bcc144b4aad45ee75130c1d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial:\n",
      "  Value:  0.12440085207991047\n",
      "  Params: \n",
      "    max_depth: 4\n",
      "    learning_rate: 0.04342459396051902\n",
      "    n_estimators: 252\n",
      "    min_child_weight: 7\n",
      "    subsample: 0.6680163611417497\n",
      "    colsample_bytree: 0.656687543807701\n",
      "    reg_alpha: 1.0168201851932558e-07\n",
      "    reg_lambda: 0.9412045882345911\n"
     ]
    }
   ],
   "source": [
    "# objective function for Optuna\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1, log=True),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 7),\n",
    "        'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 1e-8, 1.0, log=True),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 1e-8, 1.0, log=True),\n",
    "        'random_state': 42\n",
    "    }\n",
    "    \n",
    "    # get model with suggested parameters\n",
    "    model = xgb.XGBRegressor(**params)\n",
    "    \n",
    "    # cross-validation\n",
    "    cv_scores = cross_val_score(\n",
    "        model, \n",
    "        X_train, \n",
    "        y_train, \n",
    "        cv=5, \n",
    "        scoring='neg_root_mean_squared_error',\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    # mean negative RMSE (Optuna minimizes objective)\n",
    "    return -cv_scores.mean()\n",
    "\n",
    "# Create and run Optuna study\n",
    "study = optuna.create_study(direction='minimize')\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "study.optimize(objective, n_trials=50, show_progress_bar=True)\n",
    "\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print(\"  Value: \", trial.value)\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f9087202",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-20T14:06:37.391521Z",
     "start_time": "2025-11-20T14:06:33.429806Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-rmse:0.41905\n",
      "[100]\tvalidation_0-rmse:0.14442\n",
      "[200]\tvalidation_0-rmse:0.13685\n",
      "[251]\tvalidation_0-rmse:0.13639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nic/git/AmesHousingPredictor/.venv/lib/python3.10/site-packages/xgboost/sklearn.py:1115: UserWarning: [11:49:38] WARNING: /Users/runner/work/xgboost/xgboost/src/c_api/c_api.cc:1575: Saving model in the UBJSON format as default.  You can use a file extension: `json` or `ubj` to choose between formats.\n",
      "  self.get_booster().save_model(fname)\n",
      "2025/11/21 11:49:40 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "/Users/nic/git/AmesHousingPredictor/.venv/lib/python3.10/site-packages/xgboost/sklearn.py:1124: UserWarning: [11:49:40] WARNING: /Users/runner/work/xgboost/xgboost/src/c_api/c_api.cc:1511: Unknown file format: `xgb`. Using UBJSON (`ubj`) as a guess.\n",
      "  self.get_booster().load_model(fname)\n",
      "Successfully registered model 'xgboost-optimized'.\n",
      "2025/11/21 11:49:48 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: xgboost-optimized, version 1\n",
      "Created version '1' of model 'xgboost-optimized'.\n",
      "\u001b[32m2025-11-21 11:49:49.140\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mapp.pipelines.training\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m64\u001b[0m - \u001b[1m\n",
      "Training Metrics:\u001b[0m\n",
      "\u001b[32m2025-11-21 11:49:49.142\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mapp.pipelines.training\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m66\u001b[0m - \u001b[1mtrain_rmse: 0.0723\u001b[0m\n",
      "\u001b[32m2025-11-21 11:49:49.143\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mapp.pipelines.training\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m66\u001b[0m - \u001b[1mtrain_mae: 0.0518\u001b[0m\n",
      "\u001b[32m2025-11-21 11:49:49.144\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mapp.pipelines.training\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m66\u001b[0m - \u001b[1mtrain_r2: 0.9657\u001b[0m\n",
      "\u001b[32m2025-11-21 11:49:49.144\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mapp.pipelines.training\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m68\u001b[0m - \u001b[1m\n",
      "Validation Metrics:\u001b[0m\n",
      "\u001b[32m2025-11-21 11:49:49.146\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mapp.pipelines.training\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m70\u001b[0m - \u001b[1mval_rmse: 0.1364\u001b[0m\n",
      "\u001b[32m2025-11-21 11:49:49.146\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mapp.pipelines.training\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m70\u001b[0m - \u001b[1mval_mae: 0.0897\u001b[0m\n",
      "\u001b[32m2025-11-21 11:49:49.147\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mapp.pipelines.training\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m70\u001b[0m - \u001b[1mval_r2: 0.9003\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run train-run-xgboost-optimized at: http://127.0.0.1:8500/#/experiments/4/runs/2017799efa5d456895dceb41b39fa408\n",
      "üß™ View experiment at: http://127.0.0.1:8500/#/experiments/4\n",
      "\n",
      "Training Metrics:\n",
      "train_rmse: 0.0723\n",
      "train_mae: 0.0518\n",
      "train_r2: 0.9657\n",
      "\n",
      "Validation Metrics:\n",
      "val_rmse: 0.1364\n",
      "val_mae: 0.0897\n",
      "val_r2: 0.9003\n"
     ]
    }
   ],
   "source": [
    "best_params = study.best_params\n",
    "best_params['random_state'] = 42\n",
    "model = xgb.XGBRegressor(**best_params)\n",
    "\n",
    "optimized_model = trainer.train(model, \"xgboost-optimized\", X_train, y_train, X_val, y_val)\n",
    "\n",
    "print(\"\\nTraining Metrics:\")\n",
    "for metric, value in trainer.train_metrics.items():\n",
    "    print(f\"{metric}: {value:.4f}\")\n",
    "\n",
    "print(\"\\nValidation Metrics:\")\n",
    "for metric, value in trainer.val_metrics.items():\n",
    "    print(f\"{metric}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa358f3",
   "metadata": {},
   "source": [
    "## Model Comparison\n",
    "\n",
    "Let's compare the performance of our baseline and optimized models to see the improvement from hyperparameter optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "049b2257",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-20T14:06:37.406857Z",
     "start_time": "2025-11-20T14:06:37.400052Z"
    },
    "execution": {
     "iopub.execute_input": "2025-11-05T05:04:26.140932Z",
     "iopub.status.busy": "2025-11-05T05:04:26.140856Z",
     "iopub.status.idle": "2025-11-05T05:04:26.146427Z",
     "shell.execute_reply": "2025-11-05T05:04:26.146236Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Model Metrics:\n",
      "rmse: 0.1497\n",
      "mae: 0.1038\n",
      "r2: 0.8799\n",
      "\n",
      "Optimized Model Metrics:\n",
      "rmse: 0.1324\n",
      "mae: 0.0882\n",
      "r2: 0.9060\n",
      "\n",
      "RMSE Improvement: 11.54%\n"
     ]
    }
   ],
   "source": [
    "from app.pipelines.training import evaluate_model\n",
    "\n",
    "# compare models on validation set\n",
    "baseline_metrics = evaluate_model(baseline_model, X_val, y_val)\n",
    "optimized_metrics = evaluate_model(optimized_model, X_val, y_val)\n",
    "\n",
    "print(\"Baseline Model Metrics:\")\n",
    "for metric, value in baseline_metrics.items():\n",
    "    print(f\"{metric}: {value:.4f}\")\n",
    "\n",
    "print(\"\\nOptimized Model Metrics:\")\n",
    "for metric, value in optimized_metrics.items():\n",
    "    print(f\"{metric}: {value:.4f}\")\n",
    "\n",
    "improvement = (baseline_metrics['rmse'] - optimized_metrics['rmse']) / baseline_metrics['rmse'] * 100\n",
    "print(f\"\\nRMSE Improvement: {improvement:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b2dbafd3efa56370",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-20T14:12:08.735992Z",
     "start_time": "2025-11-20T14:12:08.533651Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-11-21 00:03:52.484\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mapp.inference.predict\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m45\u001b[0m - \u001b[1mmlflow tracking uri set to http://127.0.0.1:5001\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca91fab00e4f4dd2943a0e3154380439",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nic/git/AmesHousingPredictor/.venv/lib/python3.10/site-packages/xgboost/sklearn.py:1124: UserWarning: [00:04:21] WARNING: /Users/runner/work/xgboost/xgboost/src/c_api/c_api.cc:1511: Unknown file format: `xgb`. Using UBJSON (`ubj`) as a guess.\n",
      "  self.get_booster().load_model(fname)\n",
      "\u001b[32m2025-11-21 00:04:21.704\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mapp.inference.predict\u001b[0m:\u001b[36mget_model\u001b[0m:\u001b[36m24\u001b[0m - \u001b[1mloaded model with id m-c783c8021046478789333ce39d5d8005\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "mlflow.pyfunc.loaded_model:\n",
       "  artifact_path: mlflow-artifacts:/1/models/m-c783c8021046478789333ce39d5d8005/artifacts\n",
       "  flavor: mlflow.xgboost\n",
       "  run_id: c8d35a215ca445c5b9d3f3c332e93d1c"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from app.pipelines.preprocessing import get_fitted_pipelines\n",
    "feature_preprocessor, target_transformer = get_fitted_pipelines(train_data)\n",
    "\n",
    "from app.inference.predict import AmesPredictor\n",
    "predictor = AmesPredictor(feature_engineer=feature_preprocessor, model_name=\"xgboost-optimized\")\n",
    "predictor.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7c2f06934ed64b82",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-20T14:12:57.781346Z",
     "start_time": "2025-11-20T14:12:57.752657Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example prediction (SalePrice): [119894.87]\n"
     ]
    }
   ],
   "source": [
    "# Example: predict on a single row from the test set (keeps original columns)\n",
    "example_row = test_data.iloc[[0]]  # DataFrame with one row\n",
    "scaled_prediction = predictor.predict(example_row)\n",
    "prediction = target_transformer.inverse_transform(scaled_prediction)\n",
    "print(\"Example prediction (SalePrice):\", prediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AmesHousingPredictor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
